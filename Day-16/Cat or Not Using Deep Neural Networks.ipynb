{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca8b3eb1",
   "metadata": {},
   "source": [
    "### 1. Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b9ff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy\n",
    "from PIL import Image\n",
    "\n",
    "# Stats Libraries\n",
    "import statistics\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Visualisazition Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Encoders and Scalars\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Modelling Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Evaluation Metrics Libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Cross Validation Libraries\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d3026e",
   "metadata": {},
   "source": [
    "### 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea7768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(val):\n",
    "    return (1/(1+np.exp(-1*val)))\n",
    "\n",
    "def relu(val):\n",
    "    return np.maximum(0,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31bc818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "\n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "\n",
    "    assert (dZ.shape == Z.shape)\n",
    "\n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "\n",
    "    Z = cache\n",
    "\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "\n",
    "    assert (dZ.shape == Z.shape)\n",
    "\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3cec77",
   "metadata": {},
   "source": [
    "### 3. Intialize Dimensions and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbb569bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would be resizing the images to 64x64x3 for having same size for training\n",
    "n_x = 12288\n",
    "hidden_layer_dims = [n_x,20,10, 5,3,1] \n",
    "learning_rate = 0.05\n",
    "\n",
    "# defaults for training\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH  = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de98bd42",
   "metadata": {},
   "source": [
    "### 4. Initialize Random Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a5daa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(hidden_layer_dims):\n",
    "    params = {}\n",
    "    for i in range(1, len(hidden_layer_dims)): \n",
    "        params[\"W\"+str(i)] = np.random.randn(hidden_layer_dims[i],hidden_layer_dims[i-1])*0.01\n",
    "        params[\"b\"+str(i)] = np.zeros((hidden_layer_dims[i],1))*0.01\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a668f1d",
   "metadata": {},
   "source": [
    "### 5. Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6da7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propogation(X, params, hidden_layer_dims):\n",
    "    cache = {}\n",
    "    L = len(params)//2\n",
    "    cache[\"A\"+str(0)] = X\n",
    "    cache[\"Z\"+str(1)] = np.dot(params[\"W1\"],X)+params[\"b1\"]\n",
    "    cache[\"A\"+str(1)] = relu(cache[\"Z1\"])\n",
    "    for i in range(1,L-1):\n",
    "        cache[\"Z\"+str(i+1)] = np.dot(params[\"W\"+str(i+1)],cache[\"A\"+str(i)])+params[\"b\"+str(i+1)]\n",
    "        cache[\"A\"+str(i+1)] = relu(cache[\"Z\"+str(i+1)])\n",
    "    cache[\"Z\"+str(L)] = np.dot(params[\"W\"+str(L)],cache[\"A\"+str(L-1)])+params[\"b\"+str(L)]\n",
    "    cache[\"A\"+str(L)] = sigmoid(cache[\"Z\"+str(L)])\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cb9be4",
   "metadata": {},
   "source": [
    "### 6. Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e79384b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(AL, Y, hidden_layer_dims):\n",
    "    m = Y.shape[1]\n",
    "    AL =  AL\n",
    "    cost = (-1/m)*np.sum(np.multiply(Y,np.log(AL))+np.multiply(1-Y,np.log(1-AL)))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b073adcb",
   "metadata": {},
   "source": [
    "### 7. Backward_Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25dfc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    \n",
    "    m = A_prev.shape[1]\n",
    "    dW = (1/m)*(np.dot(dZ,A_prev.T))\n",
    "    db = (1/m)*np.sum(dZ,axis=1,keepdims=True) \n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc297aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ =   relu_backward(dA, activation_cache)  \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ =   sigmoid_backward(dA, activation_cache)\n",
    "        \n",
    "    dA_prev, dW, db =  linear_backward(dZ, linear_cache)  \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15a5eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(Y,AL,params,cache, hidden_layer_dims):\n",
    "    grads = {}\n",
    "    m = Y.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    L = len(hidden_layer_dims)-1\n",
    "    \n",
    "    dAL = -1*(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    cache_val = ((cache[\"A\"+str(L-1)],params[\"W\"+str(L)],params[\"b\"+str(L)]),cache[\"Z\"+str(L)])\n",
    "    \n",
    "    dA_prev,dW,db = linear_activation_backward(dAL, cache_val, \"sigmoid\")\n",
    "    grads[\"dA\" + str(L-1)] = dA_prev\n",
    "    grads[\"dW\" + str(L)] = dW\n",
    "    grads[\"db\" + str(L)] = db\n",
    "    \n",
    "    for i in range(L-1,0,-1):\n",
    "        cache_val = ((cache[\"A\"+str(i-1)],params[\"W\"+str(i)],params[\"b\"+str(i)]),cache[\"Z\"+str(i)])\n",
    "        dA_prev, dW, db = linear_activation_backward(dA_prev, cache_val, \"relu\")\n",
    "        grads[\"dA\" + str(i-1)] = dA_prev\n",
    "        grads[\"dW\" + str(i)] = dW\n",
    "        grads[\"db\" + str(i)] = db\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a792f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c93d2f8",
   "metadata": {},
   "source": [
    "### 8. Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27aa25cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(params, grads, learning_rate):\n",
    "\n",
    "    parameters = params.copy()\n",
    "    L = len(parameters) // 2\n",
    "\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = params[\"W\"+ str(l+1)] - learning_rate*grads[\"dW\"+ str(l+1)]\n",
    "        parameters[\"b\" + str(l+1)] = params[\"b\"+ str(l+1)] - learning_rate*grads[\"db\"+ str(l+1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f19dcf",
   "metadata": {},
   "source": [
    "### 9. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb256000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "\n",
    "    costs = [] \n",
    "    params = initialize_weights(layers_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        caches = forward_propogation(X, params, hidden_layer_dims)\n",
    "        AL = caches[\"A\"+str(len(layers_dims)-1)]\n",
    "        cost = calculate_cost(AL, Y, hidden_layer_dims)\n",
    "        grads = backward_propagation(Y,AL,params,caches, hidden_layer_dims)    \n",
    "        params = update_parameters(params, grads, learning_rate)\n",
    "\n",
    "        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if i % 100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "    return params, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9b255f",
   "metadata": {},
   "source": [
    "### 10. Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b22ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We store the data directly in a verctorized format \n",
    "dataset_path = \"/Users/saikarna/Desktop/GitHub/Daily-Notebook/dogs-vs-cats/\"\n",
    "train_path = dataset_path+\"train/\"\n",
    "test_path = dataset_path+\"test1/\"\n",
    "\n",
    "def load_dataset(train_path):\n",
    "    X, Y =[],[]\n",
    "    for filename in os.listdir(train_path):\n",
    "        if(filename[-3:]==\"jpg\"):\n",
    "            file_path = train_path+filename\n",
    "            image= np.array(Image.open(file_path))\n",
    "            image= np.resize(image,(IMG_HEIGHT,IMG_WIDTH,3))\n",
    "            image = image.astype('float32')\n",
    "            image /= 255.  \n",
    "            X.append(image)\n",
    "            Y.append(1 if filename[0]==\"d\" else 0)\n",
    "    X,Y = np.array(X), np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ff54794",
   "metadata": {},
   "outputs": [],
   "source": [
    "X , Y = load_dataset(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c591bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ecef655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in X :  (25000, 64, 64, 3)\n",
      "Number of data points in Y :  (25000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    12500\n",
       "0    12500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of data points in X : \",X.shape)\n",
    "print(\"Number of data points in Y : \",Y.shape)\n",
    "\n",
    "## Number of Cats and Dogs\n",
    "pd.Series(Y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5a39bd",
   "metadata": {},
   "source": [
    "### 11. Vectorize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28c4b9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in X :  (25000, 64, 64, 3)\n",
      "Number of data points in Y :  (25000,)\n",
      "X-train Shape :  (16750, 64, 64, 3) Y-train Shape :  (16750,)\n",
      "X-test Shape :  (8250, 64, 64, 3) Y-test Shape :  (8250,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in X : \",X.shape)\n",
    "print(\"Number of data points in Y : \",Y.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train ,Y_test = train_test_split(X,Y,test_size = 0.33, random_state = 33)\n",
    "print(\"X-train Shape : \",X_train.shape, \"Y-train Shape : \",Y_train.shape)\n",
    "print(\"X-test Shape : \",X_test.shape, \"Y-test Shape : \",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2277d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-train Shape :  (12288, 16750) Y-train Shape :  (1, 16750)\n",
      "X-test Shape :  (12288, 8250) Y-test Shape :  (1, 8250)\n"
     ]
    }
   ],
   "source": [
    "X_train_flatten = np.array(X_train.reshape(X_train.shape[0],-1).T)\n",
    "Y_train_flatten = np.array(Y_train.reshape(Y_train.shape[0],-1).T)\n",
    "\n",
    "X_test_flatten = np.array(X_test.reshape(X_test.shape[0],-1).T)\n",
    "Y_test_flatten = np.array(Y_test.reshape(Y_test.shape[0],-1).T)\n",
    "\n",
    "print(\"X-train Shape : \",X_train_flatten.shape, \"Y-train Shape : \",Y_train_flatten.shape)\n",
    "print(\"X-test Shape : \",X_test_flatten.shape, \"Y-test Shape : \",Y_test_flatten.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a56a13f",
   "metadata": {},
   "source": [
    "### 12. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43721378",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6931471807359174\n",
      "Cost after iteration 100: 0.6931391537870447\n",
      "Cost after iteration 200: 0.6931385052605331\n",
      "Cost after iteration 300: 0.6931384528606667\n",
      "Cost after iteration 400: 0.6931384486229095\n",
      "Cost after iteration 500: 0.6931384482766383\n",
      "Cost after iteration 600: 0.693138448243376\n",
      "Cost after iteration 700: 0.6931384482356183\n"
     ]
    }
   ],
   "source": [
    "model_param, costs = train_model(X_train_flatten, Y_train_flatten, hidden_layer_dims, learning_rate = 0.05, num_iterations = 1000, print_cost=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1abd745",
   "metadata": {},
   "source": [
    "### 13. Predict and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_costs(costs, learning_rate=0.0075):\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "plot_costs(costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c2fe0",
   "metadata": {},
   "source": [
    "### Questions to ponder on\n",
    "1. Why not train with images with different sizes??\n",
    "2. How can we have autocomplete feature available for Jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (GPU)",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
